# Script para configurar o Ollama automaticamente
# Execute: .\configurar_ollama.ps1

Write-Host "üöÄ Configurando Ollama..." -ForegroundColor Cyan
Write-Host ""

# Verificar se ollama est√° instalado
Write-Host "1Ô∏è‚É£ Verificando instala√ß√£o do Ollama..." -ForegroundColor Yellow
try {
    $version = ollama --version 2>&1
    if ($LASTEXITCODE -eq 0) {
        Write-Host "   ‚úÖ Ollama est√° instalado!" -ForegroundColor Green
        Write-Host "   Vers√£o: $version" -ForegroundColor Gray
    } else {
        Write-Host "   ‚ùå Ollama n√£o encontrado no PATH" -ForegroundColor Red
        Write-Host "   üí° Solu√ß√£o: Feche e abra um NOVO terminal, ou reinicie o computador" -ForegroundColor Yellow
        exit 1
    }
} catch {
    Write-Host "   ‚ùå Ollama n√£o encontrado no PATH" -ForegroundColor Red
    Write-Host "   üí° Solu√ß√£o: Feche e abra um NOVO terminal, ou reinicie o computador" -ForegroundColor Yellow
    exit 1
}

Write-Host ""

# Verificar modelos instalados
Write-Host "2Ô∏è‚É£ Verificando modelos instalados..." -ForegroundColor Yellow
$models = ollama list 2>&1
Write-Host $models

if ($models -match "llama3.1") {
    Write-Host "   ‚úÖ Modelo llama3.1 encontrado!" -ForegroundColor Green
} else {
    Write-Host "   ‚ö†Ô∏è Modelo llama3.1 n√£o encontrado" -ForegroundColor Yellow
    Write-Host ""
    Write-Host "3Ô∏è‚É£ Baixando modelo llama3.1:8b..." -ForegroundColor Yellow
    Write-Host "   ‚è≥ Isso pode demorar alguns minutos (~13GB)..." -ForegroundColor Gray
    
    $response = Read-Host "   Deseja baixar o modelo agora? (S/N)"
    if ($response -eq "S" -or $response -eq "s") {
        ollama pull llama3.1:8b
        if ($LASTEXITCODE -eq 0) {
            Write-Host "   ‚úÖ Modelo baixado com sucesso!" -ForegroundColor Green
        } else {
            Write-Host "   ‚ùå Erro ao baixar modelo" -ForegroundColor Red
            Write-Host "   üí° Tente manualmente: ollama pull llama3.1:8b" -ForegroundColor Yellow
        }
    } else {
        Write-Host "   ‚è≠Ô∏è Pulando download. Execute depois: ollama pull llama3.1:8b" -ForegroundColor Yellow
    }
}

Write-Host ""

# Testar conex√£o
Write-Host "4Ô∏è‚É£ Testando conex√£o com Ollama..." -ForegroundColor Yellow
try {
    $testResponse = ollama run llama3.1:8b "teste" 2>&1
    if ($LASTEXITCODE -eq 0) {
        Write-Host "   ‚úÖ Ollama est√° funcionando!" -ForegroundColor Green
    } else {
        Write-Host "   ‚ö†Ô∏è Teste falhou, mas pode ser normal" -ForegroundColor Yellow
        Write-Host "   üí° Verifique se o modelo est√° instalado: ollama list" -ForegroundColor Yellow
    }
} catch {
    Write-Host "   ‚ö†Ô∏è N√£o foi poss√≠vel testar automaticamente" -ForegroundColor Yellow
}

Write-Host ""
Write-Host "‚úÖ Configura√ß√£o conclu√≠da!" -ForegroundColor Green
Write-Host ""
Write-Host "üìã Pr√≥ximos passos:" -ForegroundColor Cyan
Write-Host "   1. Teste no sistema: abra uma resposta de check-in e clique em 'Resumo'" -ForegroundColor White
Write-Host "   2. Se n√£o funcionar, execute: ollama serve" -ForegroundColor White
Write-Host "   3. Verifique os modelos: ollama list" -ForegroundColor White
Write-Host ""

